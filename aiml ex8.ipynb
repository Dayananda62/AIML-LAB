{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3af94f1",
   "metadata": {},
   "source": [
    "# 1. Refer the below given dataset.\n",
    "# Outlook   Temperature   Humidity   Wind   Played football(yes/no)\n",
    "# Sunny     Hot           High       Weak   No\n",
    "# Sunny     Hot           High       Strong No\n",
    "# Overcast  Hot           High       Weak   Yes\n",
    "# Rain      Mild          High       Weak   Yes\n",
    "# Rain      Cool          Normal     Weak   Yes\n",
    "# Rain      Cool          Normal     Strong No\n",
    "# Overcast  Cool          Normal     Strong Yes\n",
    "# Sunny     Mild          High       Weak   No\n",
    "# Sunny     Cool          Normal     Weak   Yes\n",
    "# Rain      Cool          Normal     Weak   Yes \n",
    "# Sunny     Mild          Normal     Strong Yes \n",
    "# Overcast  Mild          Normal     Strong Yes \n",
    "# Overcast  Hot           High       Strong Yes \n",
    "# Rain      Mild          High       Strong No\n",
    "\n",
    "# Create a decision tree from scratch using the above dataset using ID3 algorithm.\n",
    "\n",
    "# Given a new set of features, predict whether game will be played.\n",
    "# Outlook   Temperature   Humidity   Wind   Play\n",
    "# Rain      Hot           Normal      Weak   ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5955f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted classification for the new example is Yes.\n"
     ]
    }
   ],
   "source": [
    "# Load necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.DataFrame({\n",
    "    'Outlook': ['Rain', 'Rain', 'Overcast', 'Sunny', 'Sunny', 'Sunny', 'Overcast', 'Rain', 'Rain', 'Sunny', 'Rain', 'Overcast', 'Overcast', 'Sunny'],\n",
    "    'Temperature': ['Hot', 'Hot', 'Hot', 'Mild', 'Cool', 'Cool', 'Cool', 'Mild', 'Cool', 'Mild', 'Mild', 'Mild', 'Hot', 'Mild'],\n",
    "    'Humidity': ['High', 'High', 'High', 'High', 'Normal', 'Normal', 'Normal', 'High', 'Normal', 'Normal', 'Normal', 'High', 'Normal', 'High'],\n",
    "    'Wind': ['Weak', 'Strong', 'Weak', 'Weak', 'Weak', 'Strong', 'Strong', 'Weak', 'Weak', 'Weak', 'Strong', 'Strong', 'Weak', 'Strong'],\n",
    "    'Play': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No']\n",
    "})\n",
    "\n",
    "# Define a function to calculate the entropy of a dataset\n",
    "def entropy(data):\n",
    "    \n",
    "    # Calculate unique values and their counts\n",
    "    values, counts = np.unique(data, return_counts=True)\n",
    "    \n",
    "    # Calculate probabilities\n",
    "    probs = counts / len(data)\n",
    "    \n",
    "    # Calculate entropy using the formula\n",
    "    entropy = -np.sum(probs * np.log2(probs))\n",
    "    return entropy\n",
    "\n",
    "# Define a function to calculate the information gain of a feature\n",
    "def information_gain(data, feature):\n",
    "    \n",
    "    # Initialize feature_entropy\n",
    "    feature_entropy = 0\n",
    "    \n",
    "    # Get unique values of the feature\n",
    "    values = data[feature].unique()\n",
    "    for value in values:\n",
    "        \n",
    "        # Subset the data based on the feature value\n",
    "        subset = data[data[feature] == value]\n",
    "        \n",
    "        # Calculate subset entropy\n",
    "        subset_entropy = entropy(subset['Play'])\n",
    "        \n",
    "        # Calculate weight and add to feature_entropy\n",
    "        weight = len(subset) / len(data)\n",
    "        feature_entropy += weight * subset_entropy\n",
    "        \n",
    "    # Calculate information gain\n",
    "    information_gain = entropy(data['Play']) - feature_entropy\n",
    "    return information_gain\n",
    "\n",
    "# Define a function to build the decision tree\n",
    "def build_tree(data, features, target):\n",
    "    \n",
    "    # Base cases\n",
    "    if len(data[target].unique()) == 1:\n",
    "        return data[target].iloc[0]\n",
    "    if len(features) == 0:\n",
    "        return data[target].value_counts().idxmax()\n",
    "    \n",
    "    # Choose the feature with the highest information gain\n",
    "    information_gains = [information_gain(data, feature) for feature in features]\n",
    "    best_feature_index = np.argmax(information_gains)\n",
    "    best_feature = features[best_feature_index]\n",
    "    \n",
    "    # Create a new decision tree node\n",
    "    tree = {best_feature: {}}\n",
    "    \n",
    "    # Remove the best feature from the feature list\n",
    "    features = [feature for feature in features if feature != best_feature]\n",
    "    \n",
    "    # Recursively build the subtree for each value of the best feature\n",
    "    for value in data[best_feature].unique():\n",
    "        subset = data[data[best_feature] == value]\n",
    "        subtree = build_tree(subset, features, target)\n",
    "        tree[best_feature][value] = subtree\n",
    "    return tree\n",
    "\n",
    "# Build the decision tree\n",
    "features = ['Outlook', 'Temperature', 'Humidity', 'Wind']\n",
    "target = 'Play'\n",
    "tree = build_tree(data, features, target)\n",
    "\n",
    "# Define a function to predict the classification of a new example\n",
    "def predict(example, tree):\n",
    "    for feature, subtree in tree.items():\n",
    "        value = example[feature]\n",
    "        subtree = subtree[value]\n",
    "        if isinstance(subtree, dict):\n",
    "            return predict(example, subtree)\n",
    "        else:\n",
    "            return subtree\n",
    "\n",
    "# Example usage\n",
    "new_example = {'Outlook': 'Sunny', 'Temperature': 'Normal', 'Humidity': 'High', 'Wind': 'Weak'}\n",
    "prediction = predict(new_example, tree)\n",
    "print(f'The predicted classification for the new example is {prediction}.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d37353d",
   "metadata": {},
   "source": [
    "# 2. For the same above problem create a decision tree using  scikit learn API. Predict for the new set of features given as in the question 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea8e9041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted classification for the new example is Yes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raosu\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.DataFrame({\n",
    "    'Outlook': ['Rain', 'Rain', 'Overcast', 'Sunny', 'Sunny', 'Sunny', 'Overcast', 'Rain', 'Rain', 'Sunny', 'Rain', 'Overcast', 'Overcast', 'Sunny'],\n",
    "    'Temperature': ['Hot', 'Hot', 'Hot', 'Mild', 'Cool', 'Cool', 'Cool', 'Mild', 'Cool', 'Mild', 'Mild', 'Mild', 'Hot', 'Mild'],\n",
    "    'Humidity': ['High', 'High', 'High', 'High', 'Normal', 'Normal', 'Normal', 'High', 'Normal', 'Normal', 'Normal', 'High', 'Normal', 'High'],\n",
    "    'Wind': ['Weak', 'Strong', 'Weak', 'Weak', 'Weak', 'Strong', 'Strong', 'Weak', 'Weak', 'Weak', 'Strong', 'Strong', 'Weak', 'Strong'],\n",
    "    'Play': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No']\n",
    "})\n",
    "\n",
    "# Encode the categorical features\n",
    "encoder = LabelEncoder()\n",
    "data['Outlook'] = encoder.fit_transform(data['Outlook'])\n",
    "data['Temperature'] = encoder.fit_transform(data['Temperature'])\n",
    "data['Humidity'] = encoder.fit_transform(data['Humidity'])\n",
    "data['Wind'] = encoder.fit_transform(data['Wind'])\n",
    "data['Play'] = encoder.fit_transform(data['Play'])\n",
    "\n",
    "# Split the dataset into features and target\n",
    "features = ['Outlook', 'Temperature', 'Humidity', 'Wind']\n",
    "target = 'Play'\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "\n",
    "# Build the decision tree\n",
    "tree = DecisionTreeClassifier(criterion='entropy')\n",
    "tree.fit(X, y)\n",
    "\n",
    "# Predict the classification of a new example\n",
    "new_example = [[0, 1, 0, 1]]  # Sunny, Normal, High, Weak\n",
    "prediction = encoder.inverse_transform(tree.predict(new_example))[0]\n",
    "print(f'The predicted classification for the new example is {prediction}.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e369967",
   "metadata": {},
   "source": [
    "# 3. Implement KNN on Social Network Ads.csv. Find the Accuracy of classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "154c2c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9000\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv('C:/Users/raosu/Documents/Assignment 8 aiml/Social_Network_Ads.csv')\n",
    "\n",
    "# Considering two features for classification (Age and EstimatedSalary)\n",
    "X = data.iloc[:, [2, 3]].values  # Assuming columns 2 and 3 are 'Age' and 'EstimatedSalary'\n",
    "y = data.iloc[:, -1].values  # Assuming the last column is the target 'Purchased'\n",
    "\n",
    "# Feature scaling (standardization)\n",
    "X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
    "\n",
    "# Function to calculate Euclidean distance\n",
    "def euclidean_distance(a, b):\n",
    "    return np.sqrt(np.sum((a - b) ** 2))\n",
    "\n",
    "# Function to perform KNN classification\n",
    "def KNN_predict(X_train, y_train, X_test, k):\n",
    "    predictions = []\n",
    "    for test_point in X_test:\n",
    "        distances = []\n",
    "        for train_point in X_train:\n",
    "            dist = euclidean_distance(test_point, train_point)\n",
    "            distances.append(dist)\n",
    "        nearest_indices = np.argsort(distances)[:k]  # Indices of k nearest neighbors\n",
    "        nearest_labels = [y_train[i] for i in nearest_indices]\n",
    "        predicted_label = max(set(nearest_labels), key=nearest_labels.count)\n",
    "        predictions.append(predicted_label)\n",
    "    return predictions\n",
    "\n",
    "# Splitting the data into training and test sets (80% train, 20% test)\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "# Define the value of K\n",
    "k = 5\n",
    "\n",
    "# Make predictions\n",
    "predictions = KNN_predict(X_train, y_train, X_test, k)\n",
    "\n",
    "# Calculate accuracy\n",
    "correct = sum(predictions[i] == y_test[i] for i in range(len(predictions)))\n",
    "accuracy = correct / len(predictions)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9488b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
